{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd3c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 23 22:27:16 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.83       Driver Version: 528.83       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   40C    P8     5W /  30W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4988    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#Checking if GPU is running or not\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f635d01-de7b-483e-b5c5-4db2f6d53f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933c94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd6926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3225bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167aac34-e386-482b-a4b3-09c37d59a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (2023.8.8)\n",
      "Requirement already satisfied: requests in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (4.66.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from transformers[sentencepiece]) (4.24.3)\n",
      "Requirement already satisfied: fsspec in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[sentencepiece]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[sentencepiece]) (4.5.0)\n",
      "Requirement already satisfied: colorama in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from requests->transformers[sentencepiece]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in n:\\deep learning project\\rnn\\english-to-hindi-translator\\englist_to_hindi\\lib\\site-packages (from requests->transformers[sentencepiece]) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a7d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers[sentencepiece] sacrebleu -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc6a79-15f9-497e-92a5-16a00e4da9a6",
   "metadata": {},
   "source": [
    "# english to hindi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e1e9107-686f-4284-a2e9-9231f435f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddde63-ff0f-412c-9102-636679c803c2",
   "metadata": {},
   "source": [
    "# loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54954e8-36e7-49cd-a51e-37207ee9c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74634d39-2943-4303-83c8-f8f60c595a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1659083\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 520\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2507\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748dc3fc-6f16-4d4e-b920-ee292f377dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'Give your application an accessibility workout',\n",
       "  'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45069c66-fb9d-4c27-96c0-78573265ccc0",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49b72620-3704-4a29-b09c-2264ecb98760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170c99d1fd1e4474bfd3b2df5633dc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\deep learning project\\RNN\\english-to-hindi-translator\\englist_to_hindi\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b7255a3953446683743d2c35dceca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a79cdd1b204151b5a5e073d9ed5335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\deep learning project\\RNN\\english-to-hindi-translator\\englist_to_hindi\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf056e1-7275-480b-bbe8-060ddb11c7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [155, 300, 23, 6532, 1659, 568, 23327, 2326, 3813, 6915, 8494, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"my name is nitin budhlakoti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ab98e07-fbe2-45bc-8b64-f152f8eac88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[500, 179, 21441, 5138, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N:\\deep learning project\\RNN\\english-to-hindi-translator\\englist_to_hindi\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"मेरा नाम नितिन है\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bded245-e833-4112-9ee6-131b9e644308",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "source_lang = \"en\"\n",
    "target_lang = \"hi\"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    # print(inputs)\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "138ba826-4425-4873-a37e-c2f886e73b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5147b90c-0513-47f0-a911-469f0f17bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5adca8b913d4410adaf0e69873313f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1659083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb856faf63f04181a80e0bce0136f1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690ac13989504694aa8dcce5f2c1e38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bbf7c17-9d44-4794-9bc3-95ea0e43a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6d4e7408-d86c-41f1-afec-a22f2582e61e)')' thrown while requesting HEAD https://huggingface.co/Helsinki-NLP/opus-mt-en-hi/resolve/main/config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fec2e76910349fbbabfa91c6ee60ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de0cec9c1de444e8343db4196f86b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30216033-d803-4594-bc27-cc1a764eaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "759d81ff-358b-4e30-80e4-8a628dc9e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "febfd79e-00ca-4217-adea-ea94feafc20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForSeq2Seq(tokenizer=MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-hi', vocab_size=61950, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True), model=<transformers.models.marian.modeling_tf_marian.TFMarianMTModel object at 0x0000029C375B9090>, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='tf')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ea50766-52b4-443c-b06d-f5566396d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59e32660-faf8-4044-90ce-f53ea9a028c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForSeq2Seq(tokenizer=MarianTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-hi', vocab_size=61950, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True), model=<transformers.models.marian.modeling_tf_marian.TFMarianMTModel object at 0x0000029C375B9090>, padding=True, max_length=None, pad_to_multiple_of=128, label_pad_token_id=-100, return_tensors='tf')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27b8c85b-ef1b-42fb-b1a5-144aebdb78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e671b626-2132-49b5-88db-97b869abbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3d325dd-57f7-4d3c-a67e-db564d26ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b853b734-87a6-4323-8cad-5c4571345a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa79feb1-45a2-407f-842b-fb96e3ef12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 502s 3s/step - loss: 3.5568 - val_loss: 3.8759\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 470s 3s/step - loss: 3.2054 - val_loss: 3.8324\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 465s 3s/step - loss: 2.9382 - val_loss: 3.8164\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 463s 3s/step - loss: 2.6962 - val_loss: 3.8033\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 467s 3s/step - loss: 2.4993 - val_loss: 3.8035\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 463s 3s/step - loss: 2.3184 - val_loss: 3.8186\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 465s 3s/step - loss: 2.1592 - val_loss: 3.8284\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 474s 3s/step - loss: 2.0032 - val_loss: 3.8465\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 475s 3s/step - loss: 1.8598 - val_loss: 3.8675\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 545s 3s/step - loss: 1.7319 - val_loss: 3.8881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29d18d8add0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_training\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6982661-8cab-4f84-ab36-c4934bbc0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd3fce2e-c048-4615-9668-7e768f43ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73800a9c-42ac-4ba6-8ddf-5d852fd295d4",
   "metadata": {},
   "source": [
    "# model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5ed7f84-79db-4a4a-ac47-4ef99f161f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 274462cb-8a14-4197-8b83-85d7f79280e1)')' thrown while requesting HEAD https://huggingface.co/Helsinki-NLP/opus-mt-en-hi/resolve/main/tokenizer_config.json\n",
      "N:\\deep learning project\\RNN\\english-to-hindi-translator\\englist_to_hindi\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at tf_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cff7b64-d945-48f3-8a74-29fd8f6f1646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[61949   217   534     6  2474   313    15 13237     5    25  4452    15\n",
      "   6921     5    40     0]], shape=(1, 16), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "input_text  = \"The constitute of our country guarantees freedom of speech.\"\n",
    "\n",
    "tokenized = tokenizer([input_text], return_tensors='np')\n",
    "out = model.generate(**tokenized, max_length=128)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b4e9b53-f0e1-483f-98ce-d26c5e6ff92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हमारे देश के सदस्य होने की गारंटी है कि बोलने की स्वतंत्रता है।\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8692961-6965-4922-ba16-c6d1fe537b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_to_hindi(input_text):\n",
    "    tokenized=tokenizer([input_text],return_tensors='np')\n",
    "    out=model.generate(**tokenized,max_length=128)\n",
    "    print(out)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        print(tokenizer.decode(out[0],skip_special_tokens=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec5894fc-42bc-4527-8646-a932c7646ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=\"\"\"The advancement of technology has transformed the way governments operate. In this digital age, governments are increasingly relying on data-driven decision-making and online services to meet the needs of their citizens. From e-governance initiatives to smart city projects, technology is at the forefront of modern governance.\n",
    "\n",
    "One of the critical aspects of this transformation is the translation of government documents and information into multiple languages to ensure accessibility and inclusivity. English to Hindi translation plays a vital role in India, where Hindi is one of the official languages and widely spoken.\n",
    "\n",
    "Government agencies need robust translation tools to communicate effectively with the Hindi-speaking population. Whether its legal documents, healthcare information, or policy announcements, accurate translation is essential to convey the intended message.\n",
    "\n",
    "However, translation is not just about converting words from one language to another. It involves capturing the nuances of language, understanding cultural sensitivities, and ensuring the accuracy of the content. This is especially crucial in government communications, where precision and clarity are paramount.\n",
    "\n",
    "As governments continue to expand their digital footprint, the demand for reliable translation services will only increase. Its not just a matter of convenience; its a matter of equitable access to government information and services.\n",
    "\n",
    "In conclusion, the role of English to Hindi translation in government operations cannot be overstated. It bridges language gaps, promotes transparency, and empowers citizens to engage with their government. As technology continues to evolve, so too will the tools and solutions available for seamless translation, making government services more accessible and efficient for all.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b97aa38-bf79-4a64-96e8-7c663c0dadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[61949 34882    15  4991    37   108   438    24  7001    78     5     2\n",
      "    263   163    12 11501    37  7284    15     5    40    89   201     2\n",
      "  11501    37    63 21324    15  5483   966    18   444    91     6    39\n",
      "   4977    69 26901   314  5048  1231  4871 23862    33 12060   246    12\n",
      "   5584    78     5    40    60  6073  1463  1266     6  6819  5249    28\n",
      "     40    89  3305     6   207    11  3527     6  7001     6    38  5011\n",
      "   5249     5     2  1231  1265  1152    11  1447    15 10359     2  1231\n",
      "    510   204    25    60   181    47 22320  1152    11  3321    29    78\n",
      "    209   168    40    89  1426    11     2  3451   169  3527     6    99\n",
      "     18  8634 29862   260 16888   260 16888   260 16888   246    11  3321\n",
      "     91    15  5483    29     5     2  1231     0]], shape=(1, 128), dtype=int32)\n",
      "प्रौद्योगिकी की प्रगति ने उस प्रकार का विकास किया है, जिस तरह से सरकारों ने कार्रवाई की है। इस समय, सरकारों ने अपने नागरिकों की आवश्यकताओं को पूरा करने के लिए डेटा-चालन निर्णय तथा ऑनलाइन सेवाओं पर व्यापक रूप से निर्भर किया है। यह आधुनिक शहर परियोजना के प्रमुख पहलू हैं। इस बदलाव के बारे में सरकार के विकास के एक महत्वपूर्ण पहलू है, तथा इसकी भाषा में पहुँच की सुविधा, तथा इससे पहले कि यह किसी भी सटीक भाषा में सुधार नहीं किया जा सकता। इस मामले में, जहां तक सरकार के लोगों को संवैधानिकानिकानिक रूप में सुधार करने की आवश्यकता नहीं है, तथा\n"
     ]
    }
   ],
   "source": [
    "english_to_hindi(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a5c16-ab1b-4537-a5b8-59244aecba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
